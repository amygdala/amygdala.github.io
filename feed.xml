<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Amy on GCP</title>
    <description></description>
    <link>http://amygdala.github.io/</link>
    <atom:link href="http://amygdala.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 03 Feb 2017 16:44:27 -0800</pubDate>
    <lastBuildDate>Fri, 03 Feb 2017 16:44:27 -0800</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Learning and using your own image classifications</title>
        <description>&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#transfer-learning-building-your-own-image-classifier&quot;&gt;Transfer learning: building your own image classifier&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#an-easy-way-to-use-your-trained-image-classifier&quot;&gt;An easy way to use your trained image classifier&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#an-example-app-would-you-hug-that&quot;&gt;An example app: “would you hug that?”&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#exporting-your-trained-model-to-cloud-ml&quot;&gt;Exporting your trained model to Cloud ML&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#using-the-hugs-classifier-for-prediction-with-the-cloud-ml-api&quot;&gt;Using the “hugs classifier” for prediction with the Cloud ML API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bonus-hedgehogs-vs-dandelions&quot;&gt;Bonus: Hedgehogs vs Dandelions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-next&quot;&gt;What Next?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://cloud.google.com/vision/&quot;&gt;Google Vision API&lt;/a&gt; is great for identifying labels, or categories, for a given
image. However, sometimes you want to further classify your own images, for more specialized categories that the Google
Vision API hasn’t been trained on.  E.g., maybe you’re a birdwatcher and want to recognize rare species of birds that the Vision API doesn’t do well at discriminating.  Maybe you’re a cell biologist, and want to try to automatically classify your slides.&lt;/p&gt;

&lt;p&gt;It turns out that it can be pretty straightforward to build your own neural net model to do this, via &lt;em&gt;transfer
learning&lt;/em&gt; –  bootstrapping an existing image classification model to reduce the effort needed to learn something new.&lt;/p&gt;

&lt;p&gt;In this post, we’ll take a look at an example that does that.&lt;/p&gt;

&lt;h2 id=&quot;transfer-learning-building-your-own-image-classifier&quot;&gt;Transfer learning: building your own image classifier&lt;/h2&gt;

&lt;p&gt;One such deep neural net model is the &lt;a href=&quot;http://arxiv.org/abs/1512.00567&quot;&gt;Inception&lt;/a&gt; architecture, built using &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow&lt;/a&gt;, a machine learning framework open-sourced by Google.
Google has also open-sourced the &lt;a href=&quot;https://github.com/tensorflow/models/tree/master/inception&quot;&gt;Inception v3&lt;/a&gt; model, trained to classify images against 1000 different &lt;a href=&quot;http://www.image-net.org/&quot;&gt;ImageNet&lt;/a&gt; categories.  We can use its penultimate “bottleneck” layer to train a new top layer that can recognize other classes of images: your own classes.
We’ll see that our new top layer does not need to be very complex, and that we typically don’t need much data or much training of this new model, to get good results for our new image classifications.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/image-classification-3-1.png&quot; alt=&quot;Transfer learning&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There have been some great posts showing how you can &lt;a href=&quot;https://petewarden.com/2016/02/28/tensorflow-for-poets/&quot;&gt;train this new ‘top layer’ model with TensorFlow&lt;/a&gt;, and how to do this training on &lt;a href=&quot;https://cloud.google.com/blog/big-data/2016/12/how-to-train-and-classify-images-using-google-cloud-machine-learning-and-cloud-dataflow&quot;&gt;Google Cloud Machine Learning&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;an-easy-way-to-use-your-trained-image-classifier&quot;&gt;An easy way to use your trained image classifier&lt;/h2&gt;

&lt;p&gt;In this post, we’ll focus more on the next step: After you’ve trained your model, and can classify your own images, you’ll want to be able to use the model for inference (prediction). That is, given a new image, you’d like to ask: which of your categories does it fall into?&lt;/p&gt;

&lt;p&gt;You’ll often need to have these prediction capabilities scale up. Perhaps you’ve built a mobile app to (say) recognize bird species, by using your trained ML model for online species prediction. If the app becomes wildly popular, you don’t want it to stop working because it’s getting too much traffic.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/ml/&quot;&gt;Google Cloud Machine Learning&lt;/a&gt; (Cloud ML) is an easy way to do this: in addition to supporting distributed model training, Cloud ML lets you scalably serve your online predictions after the model is trained.&lt;/p&gt;

&lt;p&gt;One way to access the Cloud ML online prediction service is to use the &lt;a href=&quot;https://developers.google.com/discovery/libraries&quot;&gt;Google API Client Libraries&lt;/a&gt; to access the &lt;a href=&quot;https://cloud.google.com/ml/reference/rest/&quot;&gt;Cloud ML API&lt;/a&gt;.
That means that it is quite straightforward to build an app that classifies images according to your categories, and scales up without your needing to do anything.&lt;/p&gt;

&lt;h2 id=&quot;an-example-app-would-you-hug-that&quot;&gt;An example app: “would you hug that?”&lt;/h2&gt;

&lt;p&gt;Let’s look at an example with a … kind of goofy data set.  The code used to train this model and make this app is
&lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/tree/master/workshop_sections/transfer_learning/cloudml&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;(Note: This
post is not really a tutorial – the
&lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/README.md&quot;&gt;README&lt;/a&gt; in the repo walks you through the process of building the example in more detail.  If you want to give it a try, make sure you’ve done all the
&lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/INSTALL.md&quot;&gt;necessary setup&lt;/a&gt; first).&lt;/p&gt;

&lt;p&gt;Suppose we have a set of training images that have been labeled according to two categories: “things you might want to hug”, and “things you would not want to hug”. The ‘huggable’ dataset includes images of things like puppies and kittens.  The non-huggable dataset includes images of things with sharp edges, etc.
Now, we want to build a web app that we can upload images to, and have the app tell us whether or not the object is something “huggable”.&lt;/p&gt;

&lt;p&gt;We want our web app to work like this: If you upload an image to the app:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/yarn_octopus.png&quot; width=&quot;500&quot; alt=&quot;A yarn octopus&quot; /&gt;&lt;/p&gt;

&lt;p&gt;…the app uses the trained model to get the predicted category of the image (“hugs”? “no hugs”?).  Then the app will use the response to display the results:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/yarn_octopus_score.png&quot; width=&quot;600&quot; alt=&quot;The yarn octopus is scored as huggable&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks to Julia Ferraioli for the idea, the “hugs/no-hugs” dataset and an earlier version of the prediction web app.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We’ll train our “hugs/no-hugs” model on Cloud ML, and use the Cloud ML API to make it easy to build the prediction web app.&lt;/p&gt;

&lt;p&gt;To do this, we first need to do some &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/hugs_preproc.sh&quot;&gt;image preprocessing&lt;/a&gt;, to extract the ‘bottleneck layer’ information (the &lt;em&gt;embeds&lt;/em&gt;) from the Inception v3 model, for each image in our dataset. These embeds will form the input data for the new ‘top layer’ model that we will train.
We will use &lt;a href=&quot;https://cloud.google.com/dataflow/&quot;&gt;Cloud Dataflow&lt;/a&gt; (&lt;a href=&quot;https://beam.apache.org/&quot;&gt;Apache Beam&lt;/a&gt;)
to do this preprocessing – that is, the Beam pipeline uses the Inception v3 model to generate the inputs. We’ll save those preprocessing results in the cloud, in &lt;a href=&quot;https://cloud.google.com/storage/&quot;&gt;Google Cloud Storage&lt;/a&gt; (GCS), as &lt;a href=&quot;https://www.tensorflow.org/api_docs/python/python_io/&quot;&gt;TFRecords&lt;/a&gt;, for easy consumption by the training process.&lt;/p&gt;

&lt;p&gt;Then, we’re ready to &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/hugs_train.sh&quot;&gt;train the model&lt;/a&gt;. Follow the code link to see the specifics.
(If you follow the blog post links above, you’ll also find other examples that train using a different “flowers” dataset.)&lt;/p&gt;

&lt;p&gt;Once the model is trained, we can use it to classify new images.  If we deploy the trained model to Cloud ML, we can make prediction requests using the Cloud ML API scalably, without any other setup.  This is great, since it makes our web app very easy to write.&lt;/p&gt;

&lt;h2 id=&quot;exporting-your-trained-model-to-cloud-ml&quot;&gt;Exporting your trained model to Cloud ML&lt;/h2&gt;

&lt;p&gt;To be able to &lt;a href=&quot;https://cloud.google.com/ml/docs/how-tos/getting-predictions&quot;&gt;use a trained model for prediction&lt;/a&gt;, you will need to &lt;a href=&quot;https://cloud.google.com/ml/docs/how-tos/preparing-models#adding_input_and_output_collections_to_the_graph&quot;&gt;add input and output collections&lt;/a&gt; to your model graph.  This gives Cloud ML the necessary ‘hooks’ into your deployed model graph for running predictions and returning the results.  See &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/trainer/model.py#L343&quot;&gt;this model prediction graph definition&lt;/a&gt; for an example. You’ll also need to make sure you export (save) your model as described &lt;a href=&quot;https://cloud.google.com/ml/docs/how-tos/preparing-models#exporting_saving_the_final_model&quot;&gt;here&lt;/a&gt;, including exporting the &lt;a href=&quot;https://www.tensorflow.org/versions/r0.11/how_tos/meta_graph/&quot;&gt;MetaGraph&lt;/a&gt;.  See &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/trainer/model.py#L365&quot;&gt;this method&lt;/a&gt; for example export code.&lt;/p&gt;

&lt;p&gt;Once you’ve done that, you can deploy a trained model to Cloud ML like this.  First, “create the model” in Cloud ML – this does not define the actual model, but creates a name to associate with the model once you upload it. For example:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud beta ml models create hugs
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then, &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/model.sh&quot;&gt;deploy a &lt;em&gt;version&lt;/em&gt; of that model&lt;/a&gt; by pointing Cloud ML to the checkpointed model info that was saved as the final result of your training session.
The command to do that will look something like this:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud beta ml versions create v1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --model hugs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --origin gs://your-gcs-bucket/path/to/model
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It will take a few minutes to create the model version. Once that’s done, you can start to access it for prediction in your apps.  Each time you deploy a new version of your model, you will use a new version name.  If you have more than one version of a model, you can set one as the default.&lt;/p&gt;

&lt;h2 id=&quot;using-the-hugs-classifier-for-prediction-with-the-cloud-ml-api&quot;&gt;Using the “hugs classifier” for prediction with the Cloud ML API&lt;/h2&gt;

&lt;p&gt;Once your model is deployed, there are various ways to access it.  One easy way for initial testing is just to &lt;a href=&quot;https://cloud.google.com/ml/docs/quickstarts/prediction#use_the_online_prediction_service&quot;&gt;use the gcloud sdk from the command line&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But, for the web app, we’ll use the &lt;a href=&quot;https://developers.google.com/api-client-library/python/&quot;&gt;Google API client libs&lt;/a&gt;
instead, to call the &lt;a href=&quot;https://cloud.google.com/ml/reference/rest/v1beta1/projects/predict&quot;&gt;Cloud ML API web service&lt;/a&gt;.
So we just need to upload an image to the app; format the image data for input to our model; then just make the API
call&lt;sup&gt;&lt;a href=&quot;#footnote1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and display the response.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/motherboard.jpeg&quot; alt=&quot;a computer motherboard&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For example, if we upload this photo of a motherboard…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/motherboard_score.png&quot; width=&quot;600&quot; alt=&quot;a motherboard is scored as not huggable&quot; /&gt;&lt;/p&gt;

&lt;p&gt;… it’s judged as “not huggable”.&lt;/p&gt;

&lt;p&gt;Here is a Python code snippet showing a prediction API call:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;googleapiclient&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;discovery&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;oauth2client.client&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GoogleCredentials&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GoogleCredentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_application_default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ml_service&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;discovery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;s&quot;&gt;'ml'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'v1beta1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;credentials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ml_service&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ml_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;request_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_request_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'instances'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# This request will use the default model version.&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'projects/{}/models/{}'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;project&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ml_service&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can see more detail on how the uploaded image was formatted for the API request, and how the response was 
parsed, &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/web_server/predict_server.py&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A quokka, in contrast, is (very rightly) judged as “huggable”.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/quokka_score.png&quot; width=&quot;600&quot; alt=&quot;a quokka is scored as huggable&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bonus-hedgehogs-vs-dandelions&quot;&gt;Bonus: Hedgehogs vs Dandelions&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/hedgehog.jpg&quot; width=&quot;400&quot; alt=&quot;A hedgehog&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When I was experimenting with learning both the “hugs/no-hugs” and &lt;a href=&quot;https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/transfer_learning/cloudml/flowers_preproc.sh&quot;&gt;“flowers”&lt;/a&gt; classification models, I learned something funny&lt;sup&gt;&lt;a href=&quot;#footnote2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.  I accidentally fed the “flowers” model an image of a hedgehog.  The hedgehog was meant for the “hugs/no-hugs” model, which will reasonably classify it as “don’t hug”.&lt;/p&gt;

&lt;p&gt;It turns out that if you ask the “flowers” model what kind of flower a hedgehog is, it will classify it pretty confidently as looking most like a dandelion. This seems pretty astute of the flowers model!&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;python images_to_json.py hedgehog.jpg
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;gcloud beta ml predict --model flowers --json-instances request.json
KEY                             PREDICTION  SCORES
prediction_images/hedgehog.jpg  1           &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;0.006916556041687727, 0.9633635878562927, 0.0015918412245810032, 0.005548111163079739, 0.022190041840076447, 0.0003897929273080081]
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;gsutil cat gs://cloud-ml-data/img/flower_photos/dict.txt
daisy
dandelion
roses
sunflowers
tulips
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;(We can see this is so because &lt;code class=&quot;highlighter-rouge&quot;&gt;dandelion&lt;/code&gt; is in the ‘1’ index position in the 
flower dataset’s &lt;code class=&quot;highlighter-rouge&quot;&gt;dict.txt&lt;/code&gt;, corresponding to the prediction of ‘1’.)&lt;/p&gt;

&lt;h2 id=&quot;what-next&quot;&gt;What Next?&lt;/h2&gt;

&lt;p&gt;If you’re interested to learn more about TensorFlow and CloudML, there are many examples and tutorials on the &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;TensorFlow site&lt;/a&gt;.  The &lt;a href=&quot;https://cloud.google.com/ml/docs/&quot;&gt;Cloud ML docs&lt;/a&gt; go into much more detail on how to train and serve a model, including Cloud ML’s support for distributed training and hyperparamter tuning.&lt;/p&gt;

&lt;p&gt;(You might also be interested in the upcoming &lt;a href=&quot;https://cloudnext.withgoogle.com/&quot;&gt;Google Cloud Next&lt;/a&gt; event, where you can hear much more about what Google is doing in the Big Data &amp;amp; Machine Learning area.)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;small&gt;
&lt;span id=&quot;footnote1&quot;&gt;1&lt;/span&gt;: While the prediction service is in alpha, you may sometimes see a &lt;code class=&quot;highlighter-rouge&quot;&gt;502&lt;/code&gt; error response if you make a request after not having used the service for a while.  If you see this, just resubmit. This will not be an issue once the service moves out of alpha.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;small&gt;
&lt;span id=&quot;footnote2&quot;&gt;2&lt;/span&gt;: It’s possible that this amuses only me.&lt;/small&gt;&lt;/p&gt;

&lt;h4 id=&quot;image-credits&quot;&gt;Image credits:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://goo.gl/images/zdGnN9&quot;&gt;https://goo.gl/images/zdGnN9&lt;/a&gt; - yarn octopus&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://goo.gl/images/LmaVMu&quot;&gt;https://goo.gl/images/LmaVMu&lt;/a&gt; - motherboard&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://goo.gl/images/XTF5h0&quot;&gt;https://goo.gl/images/XTF5h0&lt;/a&gt; - quokka&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://goo.gl/images/XTF5h0&quot;&gt;https://goo.gl/images/yuFM1C&lt;/a&gt; - hedgehog&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 03 Feb 2017 00:00:00 -0800</pubDate>
        <link>http://amygdala.github.io/ml/2017/02/03/transfer_learning.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/ml/2017/02/03/transfer_learning.html</guid>
        
        <category>machine_learning</category>
        
        <category>Cloud_ML</category>
        
        
        <category>ML</category>
        
      </item>
    
      <item>
        <title>Building a Slackbot that uses the Google Cloud ML Natural Language API (and runs on Kubernetes)</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Many of us belong to some &lt;a href=&quot;https://slack.com/&quot;&gt;Slack&lt;/a&gt; communities.
Slack has an API that makes it easy to add ‘&lt;a href=&quot;https://slackhq.com/a-beginner-s-guide-to-your-first-bot-97e5b0b7843d#.iyzgmbaf0&quot;&gt;bots&lt;/a&gt;’ to a channel, that do interesting things with the posted content, and that can interact with the people on the channel.
Google’s &lt;a href=&quot;cloud.google.com/products/machine-learning/&quot;&gt;Cloud Machine Learning APIs&lt;/a&gt; make it easy to build bots with interesting and fun capabilities.&lt;/p&gt;

&lt;p&gt;Here, we’ll describe how to build such a bot, one that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;uses the &lt;a href=&quot;https://cloud.google.com/natural-language/&quot;&gt;Google Cloud ML Natural Language API&lt;/a&gt; to analyze channel content,&lt;/li&gt;
  &lt;li&gt;runs on &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; to make it easy to deploy, and&lt;/li&gt;
  &lt;li&gt;uses the &lt;a href=&quot;https://github.com/howdyai/botkit&quot;&gt;Botkit&lt;/a&gt; library to make it easy to interact with Slack.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The code for this slackbot is &lt;a href=&quot;https://github.com/GoogleCloudPlatform/nodejs-docs-samples/tree/master/language/slackbot&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;using-the-cloud-ml-natural-language-api-in-a-bot&quot;&gt;Using the Cloud ML Natural Language API in a bot&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://cloud.google.com/natural-language/&quot;&gt;Google Cloud Natural Language API&lt;/a&gt;  helps reveal the structure and meaning of text by offering powerful machine learning models for multiple languages– currently, English, Spanish, and Japanese.&lt;/p&gt;

&lt;p&gt;You can use the NL API to do &lt;strong&gt;entity recognition&lt;/strong&gt; (identifying entities and label by types such as person, organization, location, events, products and media), &lt;strong&gt;sentiment analysis&lt;/strong&gt; (understanding the overall sentiment expressed in a block of text), and &lt;strong&gt;syntax analysis&lt;/strong&gt; (sentence extraction and tokenization, identifying parts of speech, creating parse trees for each sentence, and more).&lt;/p&gt;

&lt;p&gt;Our Natural Language (NL) slackbot uses the Google Cloud NL API in two different ways.&lt;/p&gt;

&lt;h3 id=&quot;entity-detection&quot;&gt;Entity detection&lt;/h3&gt;

&lt;p&gt;First, it uses the NL API’s  &lt;a href=&quot;https://cloud.google.com/natural-language/docs/basics&quot;&gt;&lt;strong&gt;entity detection&lt;/strong&gt;&lt;/a&gt; to track the most common topics that are being discussed over time in a channel.
It does this by detecting entities in each posted message, and recording them in a database.
Then, at any time the participants in the channel can query the NL slackbot to ask it for the top N entities/topics discussed in the channel (by default, over the past week).&lt;/p&gt;

&lt;h3 id=&quot;sentiment-analysis&quot;&gt;Sentiment analysis&lt;/h3&gt;

&lt;p&gt;Additionally, the NL slackbot uses the NL API to assess
the &lt;a href=&quot;https://cloud.google.com/natural-language/docs/basics&quot;&gt;&lt;strong&gt;sentiment&lt;/strong&gt;&lt;/a&gt; of any message posted to
the channel, and if the positive or negative magnitude of the statement is
sufficiently large, it sends a ‘thumbs up’ or ‘thumbs down’ to the channel in reaction.&lt;/p&gt;

&lt;h2 id=&quot;running-the-slackbot-as-a-kubernetes-app&quot;&gt;Running the Slackbot as a Kubernetes App&lt;/h2&gt;

&lt;p&gt;Our slackbot uses &lt;a href=&quot;https://cloud.google.com/container-engine/&quot;&gt;Google Container
Engine&lt;/a&gt;, a hosted version of
&lt;a href=&quot;http://kubernetes.io&quot;&gt;Kubernetes&lt;/a&gt;, to run the bot.  This is a convenient way to launch the bot in the cloud, so that there is no need to manage it locally, and to ensure that it stays running.
It also uses &lt;a href=&quot;https://cloud.google.com/container-registry/&quot;&gt;Google Container Registry&lt;/a&gt; to store a &lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; image
for the bot.&lt;/p&gt;

&lt;p&gt;It’s useful to have the bot running in the cloud, and on a Kubernetes cluster.  While you could alternately just set it up on a VM somewhere, Kubernetes will ensure that it stays running.
If the &lt;a href=&quot;http://kubernetes.io/docs/user-guide/pods/&quot;&gt;&lt;em&gt;pod&lt;/em&gt;&lt;/a&gt; in the slackbot’s &lt;a href=&quot;http://kubernetes.io/docs/user-guide/deployments/&quot;&gt;&lt;em&gt;Deployment&lt;/em&gt;&lt;/a&gt; goes down for some reason, Kubernetes will restart it.&lt;/p&gt;

&lt;h2 id=&quot;starting-up-the-nl-slackbot&quot;&gt;Starting up the NL Slackbot&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/master/language/slackbot/README.md&quot;&gt;README&lt;/a&gt;  in the GitHub repo walks you through the process of starting up and running the slackbot.  As part of the process you’ll also
create a &lt;a href=&quot;https://api.slack.com/bot-users&quot;&gt;Slack bot user&lt;/a&gt; and get an authentication token.&lt;/p&gt;

&lt;p&gt;If you think you want to run your slackbot for a while, follow the instructions in &lt;a href=&quot;https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/master/language/slackbot/README.md#optional-create-a-slackbot-app-that-uses-persistent-storage&quot;&gt;the README section on setting up a Persistent Disk&lt;/a&gt; for the bot’s database.  That will allow the bot to be restarted without losing data.
The README also walks you through how you can test your bot locally before deploying to Kubernetes if you want.&lt;/p&gt;

&lt;p&gt;Once it’s running, invite the bot to a Slack channel.&lt;/p&gt;

&lt;h2 id=&quot;the-nl-slackbot-in-action&quot;&gt;The NL Slackbot in Action&lt;/h2&gt;

&lt;p&gt;Once your NL slackbot is running, and you’ve invited it to a channel, everyone in the channel can start to interact with it.
For the most part, the NL slackbot  will keep pretty quiet. Each time there is a post, the NL slackbot will analyze the &lt;strong&gt;entities&lt;/strong&gt; in that text. It will store those entities in a database.&lt;/p&gt;

&lt;p&gt;It will also analyze the &lt;strong&gt;sentiment&lt;/strong&gt; of the post (understanding the overall sentiment expressed in a block of text).  If the magnitude of the sentiment is greater than a certain threshold, either positive or negative, the bot will respond with a ‘thumbs up’ or ‘thumbs down’.  It doesn’t respond to all posts, only those for which the sentiment magnitude is above the threshold.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/nl_coffee_bananas_sh.png&quot; alt=&quot;Analyzing sentiment&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(If you think that this aspect of the bot is a bit annoying, it is easy to disable, or change the threshold, by looking for where it is set &lt;a href=&quot;https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/master/language/slackbot/demo_bot.js&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;At any time, you can directly ask the bot for the top entities that it has detected in channel conversation (by default, the top 20 entities over the past week).  You do this by addressing the bot with the words &lt;code class=&quot;highlighter-rouge&quot;&gt;top entities&lt;/code&gt;.
For example, if your bot is called &lt;code class=&quot;highlighter-rouge&quot;&gt;@nlpbot&lt;/code&gt;, you would ask it like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@nlpbot top entities
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then, the result might look something like the following. (At least, if you have seeded your test channel with a combination of political news and Kubernetes posts :).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/nl_slackbot_ents2_sh.png&quot; alt=&quot;Asking the bot for top entities&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-next&quot;&gt;What Next?&lt;/h2&gt;

&lt;p&gt;There are many ways that this bot could be developed further and be made more sophisticated.&lt;/p&gt;

&lt;p&gt;As just one example, you could integrate the other Cloud ML APIs as well.  You might add a capability that leverages the &lt;a href=&quot;https://cloud.google.com/vision/&quot;&gt;Cloud Vision API&lt;/a&gt; to analyze the images that people post to the channel.  Then, each time someone posted a meme image to the channel, you could use the Vision API to do OCR on the image, then pass that info to the NL API.&lt;/p&gt;

&lt;p&gt;You could also extend the NL slackbot to support more sophisticated queries on the entity database – e.g., “show me the top N PERSONS” or “top N LOCATIONS today”.
Or, you could include the wiki URLs in the results for any entities that have them. This information is currently being collected, but not displayed. That might look something like the following.  Note that “Trump” and “Donald Trump” are detected as referring to the same PERSON.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/nl_slackbot_wiki_sh.png&quot; alt=&quot;Including wiki urls in entity information&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 14 Jan 2017 00:00:00 -0800</pubDate>
        <link>http://amygdala.github.io/ml/2017/01/14/nlapi.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/ml/2017/01/14/nlapi.html</guid>
        
        <category>machine_learning</category>
        
        <category>natural_language_processing</category>
        
        <category>natural_langage_API</category>
        
        <category>kubernetes</category>
        
        
        <category>ML</category>
        
      </item>
    
      <item>
        <title>Using the Cloud Vision API with Twilio Messaging on Kubernetes</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://cloud.google.com/vision/&quot;&gt;Google Cloud Vision API&lt;/a&gt; has just moved to GA (General Availability) status.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://amy-jo.storage.googleapis.com/images/cat_and_laptop.jpg&quot; width=&quot;300&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Vision API lets you create applications that can classify images into thousands of categories (e.g., “sailboat”, “lion”… or &lt;strong&gt;cat&lt;/strong&gt; and &lt;strong&gt;laptop&lt;/strong&gt; as above); can detect faces and other objects in images (including predicting “sentiment”); can perform OCR (detection of text in images); can detect landmarks (like the Eiffel Tower); can detect logos; and can moderate for offensive content.
You can &lt;a href=&quot;https://www.youtube.com/watch?v=ud2Ipnq0pTU&quot;&gt;see Jeff Dean demoing the Vision API in this video&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/cloud-vision&quot;&gt;This github repo&lt;/a&gt; has a number of Vision API examples, written in different languages, and showing off different aspects of the Cloud Vision API. Some of the examples are simple scripts, and others are a bit more complex.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;https://github.com/GoogleCloudPlatform/cloud-vision/tree/master/python/twilio/twilio-k8s&quot;&gt;new example called ‘twilio-k8s’&lt;/a&gt; has just been added to the repo. It shows
how to run the
&lt;a href=&quot;https://github.com/GoogleCloudPlatform/cloud-vision/tree/master/python/twilio/twilio-labels&quot;&gt;“What’s That?” app&lt;/a&gt; (built by &lt;a href=&quot;http://www.blog.juliaferraioli.com/2016/02/exploring-world-using-vision-twilio.html&quot;&gt;Julia
Ferraioli&lt;/a&gt;), on
&lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The app uses &lt;a href=&quot;https://www.twilio.com&quot;&gt;Twilio&lt;/a&gt; to allow images to be texted to a given number,
then uses the &lt;a href=&quot;https://cloud.google.com/vision/&quot;&gt;Cloud Vision API&lt;/a&gt; to find labels in the image
(classify what’s in the image) and return the detected labels as a reply text.
Because the app is running on Kubernetes, it’s easy to &lt;strong&gt;scale up the app&lt;/strong&gt; to support a large number
of requests.&lt;/p&gt;

&lt;p&gt;Once you’ve set up the app on your Google Container Engine (or Kubernetes) cluster, and set up your Twilio number, you can text images to get content labelings:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://amy-jo.storage.googleapis.com/images/yard.jpg&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://amy-jo.storage.googleapis.com/images/yard.jpg&quot; width=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It’s easy to modify your own version of the app to look for additional information in the image.  I’ve in fact modifed my version of the app to look for &lt;em&gt;logos&lt;/em&gt; too. It’s fun to see how well it can do with an incomplete view of a logo:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://amy-jo.storage.googleapis.com/images/cl_bar.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://amy-jo.storage.googleapis.com/images/cl_bar.png&quot; width=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After you’ve set up your app, when you’re ready to share it, you can scale up the number of servers running on your Kubernetes cluster so that the app stays responsive.  The example’s &lt;a href=&quot;https://github.com/GoogleCloudPlatform/cloud-vision/blob/master/python/twilio/twilio-k8s/README.md&quot;&gt;README&lt;/a&gt; goes into more detail about how to do all of this.&lt;/p&gt;

&lt;p&gt;For a relatively short time, you can try it out here: (785) 336-5113.&lt;br /&gt;
This number won’t work indefinitely, though :).&lt;/p&gt;

</description>
        <pubDate>Fri, 22 Apr 2016 00:00:00 -0700</pubDate>
        <link>http://amygdala.github.io/ml/2016/04/22/vision-api.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/ml/2016/04/22/vision-api.html</guid>
        
        <category>Vision_API</category>
        
        <category>machine_learning</category>
        
        
        <category>ML</category>
        
      </item>
    
      <item>
        <title>Cloud Dataflow News</title>
        <description>&lt;p&gt;There’s been a lot happening with &lt;a href=&quot;https://cloud.google.com/dataflow/&quot;&gt;Google Cloud Dataflow&lt;/a&gt; lately.&lt;/p&gt;

&lt;p&gt;We are pleased to announce the recent induction of the &lt;a href=&quot;https://cloud.google.com/dataflow/what-is-google-cloud-dataflow#Sdks&quot;&gt;Google Cloud Dataflow SDK&lt;/a&gt; (and corresponding runners for &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Apache Flink&lt;/a&gt; and &lt;a href=&quot;http://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;) into the new &lt;a href=&quot;http://beam.incubator.apache.org/&quot;&gt;Apache Beam incubator project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;http://oreilly.com/ideas/the-world-beyond-batch-streaming-102&quot;&gt;‘Streaming 102’&lt;/a&gt; article was published by O’Reilly , following 
&lt;a href=&quot;http://oreilly.com/ideas/the-world-beyond-batch-streaming-101&quot;&gt;‘Streaming 101’&lt;/a&gt;.  These articles provide a great overview of design and implementation considerations in stream data analysis.&lt;/p&gt;

&lt;p&gt;We’ve also recently written an article that &lt;a href=&quot;https://cloud.google.com/dataflow/blog/dataflow-beam-and-spark-comparison&quot;&gt;compares the programming models of Dataflow and Spark as they exist today&lt;/a&gt;, based on a mobile ‘gaming’ scenario, involving the evolution of a pipeline from a simple batch use case to more sophisticated streaming use cases, with side-by-side code snippets contrasting the two.
The article uses a suite of ‘gaming’ example pipelines that can be found in the &lt;a href=&quot;https://github.com/GoogleCloudPlatform/DataflowJavaSDK/tree/master/examples/src/main/java8/com/google/cloud/dataflow/examples/complete/game&quot;&gt;Dataflow github repo&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Mon, 15 Feb 2016 00:00:00 -0800</pubDate>
        <link>http://amygdala.github.io/dataflow/2016/02/15/dataflow.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/dataflow/2016/02/15/dataflow.html</guid>
        
        <category>Apache_Beam</category>
        
        <category>big_data</category>
        
        <category>data_analysis</category>
        
        
        <category>Dataflow</category>
        
      </item>
    
      <item>
        <title>New sample repos for Symfony and Laravel with the Google App Engine PHP Runtime</title>
        <description>&lt;p&gt;After the recent &lt;a href=&quot;http://amygdala.github.io/gae/php/2015/03/09/gaephp.html&quot;&gt;updates to the Google App Engine PHP Runtime&lt;/a&gt;, we are creating GAE forks for some of the popular PHP framework starter apps.  These forks contain the modifications for running these apps on App Engine.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/symfony-standard&quot;&gt;This repository&lt;/a&gt; contains a modified Symfony Standard Edition Starter app for Google App Engine.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/laravel&quot;&gt;This repository&lt;/a&gt; contains a modified Laravel Starter app for Google App Engine.&lt;/p&gt;

&lt;p&gt;To get started with either one, see the README in the repo.&lt;/p&gt;

&lt;p&gt;You’ll want to first create a Google Cloud project if you don’t already have one. You can do that from &lt;a href=&quot;https://console.developers.google.com/start/appengine&quot;&gt;this page&lt;/a&gt; if you like.  (Note that there is a &lt;a href=&quot;https://console.developers.google.com/billing/freetrial&quot;&gt;free trial&lt;/a&gt; available).&lt;/p&gt;

&lt;p&gt;Then, if you’re not familiar with PHP on App Engine, you might want to follow the &lt;a href=&quot;https://cloud.google.com/appengine/docs/php/gettingstarted/introduction&quot;&gt;PHP Tutorial&lt;/a&gt; first.&lt;/p&gt;

&lt;p&gt;We’re looking forward to your feedback (and/or pull requests)!&lt;/p&gt;

</description>
        <pubDate>Wed, 20 May 2015 00:00:00 -0700</pubDate>
        <link>http://amygdala.github.io/gae/php/2015/05/20/gaephp.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/gae/php/2015/05/20/gaephp.html</guid>
        
        <category>php</category>
        
        <category>gae</category>
        
        
        <category>gae</category>
        
        <category>php</category>
        
      </item>
    
      <item>
        <title>Real-time analysis of Twitter data using Kubernetes, PubSub and BigQuery</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/pubsub/overview&quot;&gt;Google Cloud &lt;strong&gt;PubSub&lt;/strong&gt;&lt;/a&gt; provides many-to-many, asynchronous messaging that decouples senders and receivers. It allows for secure and highly available communication between independently written applications and delivers low-latency, durable messaging.
It has just gone to Beta, and is available for anyone to try.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes-bigquery-python/tree/master/pubsub&quot;&gt;This example&lt;/a&gt; &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes&quot;&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/a&gt; app shows how to build a ‘pipeline’ to stream Twitter data into &lt;a href=&quot;https://cloud.google.com/bigquery/what-is-bigquery&quot;&gt;&lt;strong&gt;BigQuery&lt;/strong&gt;&lt;/a&gt; using &lt;a href=&quot;https://cloud.google.com/pubsub/docs&quot;&gt;PubSub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The app uses uses PubSub to buffer the data coming in from Twitter and to decouple ingestion from processing.
One of the Kubernetes app &lt;strong&gt;&lt;em&gt;pods&lt;/em&gt;&lt;/strong&gt; reads the data from Twitter and publishes it to a PubSub topic.  Other pods subscribe to the PubSub topic, grab data in small batches, and stream it into BigQuery.  The figure below suggests this flow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/k8s_pubsub_tw_bq.png&quot; width=&quot;600&quot; alt=&quot;Architecture of app&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This app can be thought of as a ‘workflow’ type of app– it doesn’t have a web front end (though Kubernetes is great for those types of apps as well).
Instead, it is designed to continously run a scalable data ingestion pipeline.&lt;/p&gt;

&lt;p&gt;Find the code and more detail &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes-bigquery-python/tree/master/pubsub&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Wed, 11 Mar 2015 00:00:00 -0700</pubDate>
        <link>http://amygdala.github.io/kubernetes/2015/03/11/pubsub.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/kubernetes/2015/03/11/pubsub.html</guid>
        
        <category>kubernetes</category>
        
        <category>pubsub</category>
        
        <category>bigquery</category>
        
        <category>twitter</category>
        
        
        <category>kubernetes</category>
        
      </item>
    
      <item>
        <title>Updates to the Google App Engine PHP Runtime</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://code.google.com/p/googleappengine/wiki/SdkReleaseNotes&quot;&gt;1.9.18 Google App Engine release&lt;/a&gt; has added new capabilities to the &lt;a href=&quot;https://cloud.google.com/appengine/docs/php&quot;&gt;App Engine PHP runtime&lt;/a&gt;. 
It’s now possible to &lt;a href=&quot;https://cloud.google.com/appengine/docs/php/#PHP_Selecting_the_PHP_runtime&quot;&gt;select PHP 5.5&lt;/a&gt; as your runtime, and a number of useful new features are supported if you do so.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;cURL&lt;/strong&gt; extension is now &lt;a href=&quot;https://cloud.google.com/appengine/docs/php/#PHP_Enabled_extensions&quot;&gt;supported&lt;/a&gt;.
We’ve also provided a &lt;a href=&quot;https://cloud.google.com/appengine/docs/php/config/php_ini#GAE_directives&quot;&gt;cURL implementation using the standard HTTP streams API&lt;/a&gt; for apps that do not need the complete cURL extension.
The &lt;strong&gt;ImageMagick&lt;/strong&gt; extension is now supported for PHP 5.5 apps as well.&lt;/p&gt;

&lt;p&gt;We’ve added an in memory virtual filesystem that makes it possible to create temporary files.
In the new PHP 5.5 runtime, you can now use the &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sys_get_temp_dir()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;tmpfile()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tempnam()&lt;/code&gt;&lt;/strong&gt; functions to &lt;a href=&quot;https://gae-php-tips.appspot.com/2015/03/03/file-system-changes-in-app-engine-1-9-18/&quot;&gt;create temporary files&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The PHP 5.5. runtime also gives you the ability to &lt;a href=&quot;https://gae-php-tips.appspot.com/2015/03/09/direct-file-uploads-for-php-5-5/&quot;&gt;&lt;strong&gt;upload files directly to your application&lt;/strong&gt;&lt;/a&gt;, without the need to upload the files to &lt;a href=&quot;https://cloud.google.com/storage/docs&quot;&gt;Google Cloud Storage&lt;/a&gt; first. Direct uploads leverages the same in-memory virtual filesystem that is used to provide temporary filesystem support. Direct uploads are only available with the PHP 5.5 runtime, and are  limited to a maximum combined size of 32MB, which is the incoming request size limit.&lt;/p&gt;

&lt;p&gt;See the linked-to posts, from the unoffical “Tips and Tricks for PHP on Google App Engine” &lt;a href=&quot;https://gae-php-tips.appspot.com&quot;&gt;blog&lt;/a&gt;, for more detail, and the App Engine &lt;a href=&quot;https://code.google.com/p/googleappengine/wiki/SdkReleaseNotes&quot;&gt;release notes&lt;/a&gt; for more detail on what has changed.&lt;/p&gt;

</description>
        <pubDate>Mon, 09 Mar 2015 00:00:00 -0700</pubDate>
        <link>http://amygdala.github.io/gae/php/2015/03/09/gaephp.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/gae/php/2015/03/09/gaephp.html</guid>
        
        <category>php</category>
        
        <category>gae</category>
        
        
        <category>gae</category>
        
        <category>php</category>
        
      </item>
    
      <item>
        <title>Persistent Installation of MySQL and WordPress on Kubernetes</title>
        <description>&lt;p&gt;This post describes how to run a persistent installation of &lt;a href=&quot;https://wordpress.org/&quot;&gt;Wordpress&lt;/a&gt; on &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes&quot;&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We’ll use the &lt;a href=&quot;https://registry.hub.docker.com/_/mysql/&quot;&gt;mysql&lt;/a&gt; and &lt;a href=&quot;https://registry.hub.docker.com/_/wordpress/&quot;&gt;wordpress&lt;/a&gt; official &lt;a href=&quot;https://www.docker.com/&quot;&gt;Docker&lt;/a&gt; images for this installation. (The wordpress image includes an Apache server).&lt;/p&gt;

&lt;p&gt;We’ll create two Kubernetes &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/pods.md&quot;&gt;pods&lt;/a&gt; to run mysql and wordpress, both with associated &lt;a href=&quot;https://cloud.google.com/compute/docs/disks&quot;&gt;persistent disks&lt;/a&gt;, then set up a Kubernetes &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md&quot;&gt;service&lt;/a&gt; to front each pod.&lt;/p&gt;

&lt;p&gt;This example demonstrates several useful things, including: how to set up and use persistent disks with Kubernetes pods; how to define Kubernetes services to leverage docker-links-compatible service environment variables; and use of an external load balancer to expose the wordpress service externally and make it transparent to the user if the wordpress pod moves to a different cluster node.&lt;/p&gt;

&lt;p&gt;Some of the post details, such as the Persistent Disk setup, require that Kubernetes is running on &lt;a href=&quot;https://cloud.google.com/compute/&quot;&gt;Google Compute Engine&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;install-gcloud-and-start-up-a-kubernetes-cluster&quot;&gt;Install gcloud and Start up a Kubernetes Cluster&lt;/h2&gt;

&lt;p&gt;First, if you have not already done so, &lt;a href=&quot;https://cloud.google.com/compute/docs/quickstart&quot;&gt;create&lt;/a&gt; a &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud Platform&lt;/a&gt; project, and install the &lt;a href=&quot;https://cloud.google.com/sdk/&quot;&gt;gcloud SDK&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Then, set the gcloud default project name to point to the project you want to use for your Kubernetes cluster:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud config set project &amp;lt;project-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Next, grab the Kubernetes &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/releases&quot;&gt;release binary&lt;/a&gt;.  (This example was tested with release 0.8.1).&lt;/p&gt;

&lt;p&gt;Then, start up a &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes&quot;&gt;Kubernetes&lt;/a&gt; &lt;a href=&quot;...&quot;&gt;cluster&lt;/a&gt; as &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/gce.md&quot;&gt;described here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ &amp;lt;kubernetes&amp;gt;/cluster/kube-up.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;kubernetes&amp;gt;&lt;/code&gt; is the path to your Kubernetes installation.&lt;/p&gt;

&lt;h2 id=&quot;create-and-format-two-persistent-disks&quot;&gt;Create and format two persistent disks&lt;/h2&gt;

&lt;p&gt;For this WordPress installation, we’re going to configure our Kubernetes &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/pods.md&quot;&gt;pods&lt;/a&gt; to use &lt;a href=&quot;https://cloud.google.com/compute/docs/disks&quot;&gt;persistent disks&lt;/a&gt;. This means that we can preserve installation state across pod shutdown and re-startup.&lt;/p&gt;

&lt;p&gt;Before doing anything else, we’ll create and format the persistent disks that we’ll use for the installation: one for the mysql pod, and one for the wordpress pod.
The general series of steps required is as described &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md&quot;&gt;here&lt;/a&gt;, where $ZONE is the zone where your cluster is running, and $DISK_SIZE is specified as, e.g. ‘500GB’.  In future, this process will be more streamlined.&lt;/p&gt;

&lt;p&gt;So for the two disks used in this example, do the following.
First create and format the mysql disk, setting the disk size to meet your needs:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gcloud compute disks create --size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$DISK_SIZE&lt;/span&gt; --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; mysql-disk
gcloud compute instances attach-disk --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; --disk&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;mysql-disk --device-name temp-data kubernetes-master
gcloud compute ssh --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; kubernetes-master &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --command &lt;span class=&quot;s2&quot;&gt;&quot;sudo mkdir /mnt/tmp &amp;amp;&amp;amp; sudo /usr/share/google/safe_format_and_mount /dev/disk/by-id/google-temp-data /mnt/tmp&quot;&lt;/span&gt;
gcloud compute instances detach-disk --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; --disk mysql-disk kubernetes-master&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Then create and format the wordpress disk.  Note that you may not want as large a disk size for the wordpress code as for the mysql disk.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gcloud compute disks create --size&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$DISK_SIZE&lt;/span&gt; --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; wordpress-disk
gcloud compute instances attach-disk --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; --disk&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$wordpress&lt;/span&gt;-disk --device-name temp-data kubernetes-master
gcloud compute ssh --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; kubernetes-master &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --command &lt;span class=&quot;s2&quot;&gt;&quot;sudo mkdir /mnt/tmp &amp;amp;&amp;amp; sudo /usr/share/google/safe_format_and_mount /dev/disk/by-id/google-temp-data /mnt/tmp&quot;&lt;/span&gt;
gcloud compute instances detach-disk --zone&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE&lt;/span&gt; --disk wordpress-disk kubernetes-master&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;start-the-mysql-pod-and-service&quot;&gt;Start the Mysql Pod and Service&lt;/h2&gt;

&lt;p&gt;Now that the persistent disks are defined, the Kubernetes pods can be launched.  We’ll start with the mysql pod.&lt;/p&gt;

&lt;h3 id=&quot;start-the-mysql-pod&quot;&gt;Start the Mysql pod&lt;/h3&gt;

&lt;p&gt;Copy and then edit this &lt;a href=&quot;https://gist.github.com/amygdala/88a8740e3946ba55125b&quot;&gt;mysql.yaml&lt;/a&gt; pod definition to use the database password you specify.  &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql.yaml&lt;/code&gt; looks like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;desiredState&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;manifest&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MYSQL_ROOT_PASSWORD&lt;/span&gt;
           &lt;span class=&quot;c1&quot;&gt;# change this&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yourpassword&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;100&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerPort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3306&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;volumeMounts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# name must match the volume name below&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-persistent-storage&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# mount path within the container&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/var/lib/mysql&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-persistent-storage&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;persistentDisk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# This GCE PD must already exist and be formatted ext4&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;pdName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql-disk&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;fsType&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ext4&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note that we’ve defined a volume mount for &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/lib/mysql&lt;/code&gt;, and specified a volume that uses the persistent disk (&lt;code class=&quot;highlighter-rouge&quot;&gt;mysql-disk&lt;/code&gt;) that you created.
Once you’ve edited the file to set your database password, create the pod as follows, where &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;kubernetes&amp;gt;&lt;/code&gt; is the path to your Kubernetes installation:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh create -f mysql.yaml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;It may take a short period before the new pod reaches the &lt;code class=&quot;highlighter-rouge&quot;&gt;Running&lt;/code&gt; state.
List all pods to see the status of this new pod and the cluster node that it is running on:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh get pods&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;check-the-running-pod-on-the-compute-instance&quot;&gt;Check the running pod on the Compute instance&lt;/h4&gt;

&lt;p&gt;You can take a look at the logs for a pod by using &lt;code class=&quot;highlighter-rouge&quot;&gt;kubectl.sh log&lt;/code&gt;.  For example:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh log mysql&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you want to do deeper troubleshooting, e.g. if it seems a container is not staying up, you can also ssh in to the node that a pod is running on.  There, you can run &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo -s&lt;/code&gt;, then &lt;code class=&quot;highlighter-rouge&quot;&gt;docker ps -a&lt;/code&gt; to see all the containers.  You can then inspect the logs of containers that have exited, via &lt;code class=&quot;highlighter-rouge&quot;&gt;docker logs &amp;lt;container_id&amp;gt;&lt;/code&gt;.  (You can also find some relevant logs under &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/log&lt;/code&gt;, e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.log&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;kubelet.log&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&quot;start-the-myql-service&quot;&gt;Start the Myql service&lt;/h3&gt;

&lt;p&gt;We’ll define and start a &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md&quot;&gt;service&lt;/a&gt; that lets other pods access the mysql database on a known port and host.
We will specifically name the service &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt;.  This will let us leverage the support for &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md#how-do-they-work&quot;&gt;Docker-links-compatible&lt;/a&gt; serviceenvironment variables when we up the wordpress pod. The wordpress Docker image expects to be linked to a mysql container named &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt;, as you can see in the “How to use this image” section on the wordpress docker hub &lt;a href=&quot;https://registry.hub.docker.com/_/wordpress/&quot;&gt;page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So if we label our Kubernetes mysql service &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt;, the wordpress pod will be able to use the Docker-links-compatible environment variables, defined by Kubernetes, to connect to the database.&lt;/p&gt;

&lt;p&gt;Copy the &lt;a href=&quot;https://gist.github.com/amygdala/9f88e2ea9c37d26a8a68&quot;&gt;mysql-service.yaml&lt;/a&gt; file, which looks like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Service&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the port that this service should serve on&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3306&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# just like the selector in the replication controller,&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# but this time it identifies the set of pods to load balance&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# traffic to.&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the container on each pod to connect to, can be a name&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# (e.g. 'www') or a number (e.g. 80)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;containerPort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3306&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mysql&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Then, start the service like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh create -f mysql-service.yaml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see what services are running via:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh get services&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;start-wordpress-pod-and-service&quot;&gt;Start WordPress Pod and Service&lt;/h2&gt;

&lt;p&gt;Once the mysql service is up, start the wordpress pod.&lt;/p&gt;

&lt;p&gt;Copy this pod config file: &lt;a href=&quot;https://gist.github.com/amygdala/ccf107f940054ae5d740&quot;&gt;wordpress.yaml&lt;/a&gt; and edit the database password to be the same as you used in &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql.yaml&lt;/code&gt;. Note that this config file also defines a volume, this one using the &lt;code class=&quot;highlighter-rouge&quot;&gt;wordpress-disk&lt;/code&gt; persistent disk that you created.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;desiredState&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;manifest&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;frontendController&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;containerPort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;80&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;volumeMounts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# name must match the volume name below&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress-persistent-storage&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# mount path within the container&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;mountPath&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/var/www/html&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;WORDPRESS_DB_PASSWORD&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# change this&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;yourpassword&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress-persistent-storage&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;# emptyDir: {}&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;persistentDisk&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# This GCE PD must already exist and be formatted ext4&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;pdName&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wordpress-disk&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;fsType&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ext4&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;frontend&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Pod&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Create the pod:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh create -f wordpress.yaml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And list the pods to check that the status of the new pod changes to &lt;code class=&quot;highlighter-rouge&quot;&gt;Running&lt;/code&gt;.  As above, this might take a minute.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh get pods&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;start-the-wordpress-service&quot;&gt;Start the WordPress service&lt;/h3&gt;

&lt;p&gt;Once the wordpress pod is running, start its service.  Copy
&lt;a href=&quot;https://gist.github.com/amygdala/72128b4624a7c9317a45&quot;&gt;wordpress-service.yaml&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The service config file looks like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Service&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;v1beta1&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;frontend&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the port that this service should serve on&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# just like the selector in the replication controller,&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# but this time it identifies the set of pods to load balance&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# traffic to.&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;selector&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;frontend&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the container on each pod to connect to, can be a name&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# (e.g. 'www') or a number (e.g. 80)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;containerPort&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;80&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;frontend&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;createExternalLoadBalancer&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note the &lt;code class=&quot;highlighter-rouge&quot;&gt;createExternalLoadBalancer&lt;/code&gt; setting.  This will set up the wordpress service behind an external IP.
&lt;code class=&quot;highlighter-rouge&quot;&gt;createExternalLoadBalancer&lt;/code&gt; only works on GCE.&lt;/p&gt;

&lt;p&gt;Note also that we’ve set the service port to 3000.  We’ll return to that shortly.&lt;/p&gt;

&lt;p&gt;Start the service:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh create -f wordpress-service.yaml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;and see it in the list of services:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh get services&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Then, find the external IP for your WordPress service by listing the forwarding rules for your project:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ gcloud compute forwarding-rules list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Look for the rule called &lt;code class=&quot;highlighter-rouge&quot;&gt;frontend&lt;/code&gt;, which is what we named the wordpress service, and note its IP address.&lt;/p&gt;

&lt;h2 id=&quot;visit-your-new-wordpress-blog&quot;&gt;Visit your new WordPress blog&lt;/h2&gt;

&lt;p&gt;To access your new installation, you’ll first need to open up port 3000 (the port specified in the wordpress service config) in the firewall. Do this via:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ gcloud compute firewall-rules create wordpress --allow tcp:3000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This will define a firewall rule called &lt;code class=&quot;highlighter-rouge&quot;&gt;wordpress&lt;/code&gt; that opens port 3000 in the default network for your project.&lt;/p&gt;

&lt;p&gt;Now, we can visit the running WordPress app.
Use the external IP that you obtained above, and visit it on port 3000:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;http://&amp;lt;external_ip&amp;gt;:3000
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You should see the familiar WordPress init page.&lt;/p&gt;

&lt;h2 id=&quot;take-down-and-restart-your-blog&quot;&gt;Take down and restart your blog&lt;/h2&gt;

&lt;p&gt;Set up your WordPress blog and play around with it a bit.  Then, take down its pods and bring them back up again. Because you used persistent disks, your blog state will be preserved.&lt;/p&gt;

&lt;p&gt;If you are just experimenting, you can take down and bring up only the pods:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh delete -f wordpress.yaml
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&amp;lt;kubernetes&amp;gt;/cluster/kubectl.sh delete -f mysql.yaml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;When you restart the pods again (using the &lt;code class=&quot;highlighter-rouge&quot;&gt;create&lt;/code&gt; operation as described above), their services will pick up the new pods based on their labels.&lt;/p&gt;

&lt;p&gt;If you want to shut down the entire app installation, you can delete the services as well.&lt;/p&gt;

&lt;p&gt;If you are ready to turn down your Kubernetes cluster altogether, run:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ &amp;lt;kubernetes&amp;gt;/cluster/kube-down.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 13 Jan 2015 00:00:00 -0800</pubDate>
        <link>http://amygdala.github.io/kubernetes/2015/01/13/k8s1.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/kubernetes/2015/01/13/k8s1.html</guid>
        
        
        <category>kubernetes</category>
        
      </item>
    
      <item>
        <title>Tutorial: Real-time analysis of Twitter data using Kubernetes, Redis and BigQuery</title>
        <description>&lt;p&gt;This is a &lt;a href=&quot;https://cloud.google.com/solutions/real-time-analysis/kubernetes-redis-bigquery&quot;&gt;tutorial&lt;/a&gt; and &lt;a href=&quot;https://github.com/GoogleCloudPlatform/kubernetes-bigquery-python/&quot;&gt;sample app&lt;/a&gt; showing how to use &lt;a href=&quot;http://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt; and &lt;a href=&quot;https://cloud.google.com/bigquery/&quot;&gt;BigQuery&lt;/a&gt;, along with Redis, to support real-time analysis of Twitter data.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/k8s_redis_tw_bq.png&quot; width=&quot;600&quot; alt=&quot;Architecture of app&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Jan 2015 00:00:00 -0800</pubDate>
        <link>http://amygdala.github.io/kubernetes/2015/01/11/k8s2.html</link>
        <guid isPermaLink="true">http://amygdala.github.io/kubernetes/2015/01/11/k8s2.html</guid>
        
        <category>kubernetes</category>
        
        <category>bigquery</category>
        
        <category>redis</category>
        
        <category>twitter</category>
        
        
        <category>kubernetes</category>
        
      </item>
    
  </channel>
</rss>
