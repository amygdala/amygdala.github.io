<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Using Cloud Dataflow pipeline templates from App Engine</title>
  <meta name="description" content="Introduction">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://amygdala.github.io/dataflow/app_engine/2017/10/24/gae_dataflow.html">
  <link rel="alternate" type="application/rss+xml" title="Amy on GCP" href="http://amygdala.github.io/feed.xml" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Amy on GCP</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Using Cloud Dataflow pipeline templates from App Engine</h1>
    <p class="post-meta">Oct 24, 2017</p>
  </header>

  <article class="post-content">
    <h2 id="introduction">Introduction</h2>

<p>This post describes how to use <a href="https://cloud.google.com/dataflow/">Cloud Dataflow</a>
<a href="https://cloud.google.com/dataflow/docs/templates/overview">job templates</a>
to easily launch <a href="https://cloud.google.com/dataflow/">Dataflow</a> pipelines from a <a href="https://cloud.google.com/appengine/">Google App Engine (GAE)</a> app,
in order to support <a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce</a>
jobs and many other data processing and analysis tasks.</p>

<p>This post builds on a <a href="http://amygdala.github.io/dataflow/app_engine/2017/04/14/gae_dataflow.html">previous post</a>, which
used a <a href="https://cloud.google.com/appengine/docs/flexible/">GAE Flexible</a>
<a href="https://cloud.google.com/appengine/docs/standard/python/an-overview-of-app-engine#services_the_building_blocks_of_app_engine">service</a> 
to periodically launch a Python Dataflow pipeline.  The use of GAE Flex was necessary at the time, because we needed
to install the <a href="https://cloud.google.com/sdk/"><code class="highlighter-rouge">gcloud</code> sdk</a> in the instance container(s) in order to launch the pipelines.</p>

<p>Since then, Cloud Dataflow <a href="https://cloud.google.com/dataflow/docs/templates/overview">templates</a> have come into the
picture for the Python SDK. Dataflow templates allow you to stage your pipelines on
<a href="https://cloud.google.com/storage/">Google Cloud Storage</a> and execute them from a variety of environments.
This has a number of benefits:</p>

<ul>
  <li>With templates, you don’t have to recompile your code every time you execute a pipeline.</li>
  <li>This means that you don’t need to launch your pipeline from a development environment or worry about dependencies.</li>
  <li>It’s much easier for non-technical users to launch pipelines using templates.  You can launch via 
the <a href="https://console.cloud.google.com">Google Cloud Platform Console</a>, the <code class="highlighter-rouge">gcloud</code> command-line interface, or the REST API.</li>
</ul>

<p>In this post, we’ll show how to use the Dataflow job template
<a href="https://cloud.google.com/dataflow/docs/reference/rest/#collection-v1b3projectslocationstemplates">REST API</a>
to periodically launch a Dataflow templated job from GAE.  Because we’re now simply calling an
API, and no longer relying on the <code class="highlighter-rouge">gcloud</code> sdk to launch from App Engine, we can build a simpler <a href="https://cloud.google.com/appengine/docs/standard/">App Engine
Standard</a> app.</p>

<p>With templates, you can use
<a href="https://cloud.google.com/dataflow/docs/templates/creating-templates#modifying-your-code-to-use-runtime-parameters">runtime parameters</a>
to customize the execution.  We’ll use that feature in this example too.</p>

<p>The pipeline used in this example is nearly the same as that described in the
<a href="http://amygdala.github.io/dataflow/app_engine/2017/04/14/gae_dataflow.html">earlier post</a>; it analyzes data
stored in <a href="https://cloud.google.com/datastore/">Cloud Datastore</a> — in
this case, stored tweets fetched periodically from Twitter.
The pipeline does several sorts of analysis on the tweet data; for example, it identifies important word co-occurrences in the tweets, based on a variant of the <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">tf*idf</a> metric.</p>

<figure>
<a href="https://amy-jo.storage.googleapis.com/images/gae_dataflow/gae_dataflow_twitter_bq2.png" target="_blank"><img src="https://amy-jo.storage.googleapis.com/images/gae_dataflow/gae_dataflow_twitter_bq2.png" /></a>
<figcaption><i>Detecting important word co-occurrences in tweets</i></figcaption>
</figure>

<h2 id="defining-a-parameterized-dataflow-pipeline-and-creating-a-template">Defining a parameterized Dataflow pipeline and creating a template</h2>

<p>The first step in building our app is creating a Dataflow template. We do this by building a pipeline and then
<a href="https://cloud.google.com/dataflow/docs/templates/creating-templates#creating-and-staging-templates">deploying</a>
it with the <code class="highlighter-rouge">--template_location</code> flag, which causes the template to be compiled and stored at the given
<a href="https://cloud.google.com/storage/">Google Cloud Storage (GCS)</a> location.</p>

<p>You can see the pipeline definition <a href="https://github.com/amygdala/gae-dataflow/blob/master/job_template_launch/dfpipe/pipe.py">here</a>.
It reads recent tweets from the past N days from Cloud Datastore, then splits into three processing branches.
It finds the most popular words in terms of the percentage of tweets they were found in, calculates the most
popular URLs in terms of their count, and then derives relevant word co-occurrences using an approximation to a <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"> <em>tf*idf</em></a>
ranking metric.  It writes the results to three BigQuery tables. (It would be equally straightforward to write results
to Datastore instead/as well).</p>

<figure>
<a href="https://amy-jo.storage.googleapis.com/images/df_template_pipe.png" target="_blank"><img src="https://amy-jo.storage.googleapis.com/images/df_template_pipe.png" width="600" /></a>
<figcaption><i>The dataflow pipeline graph.</i></figcaption>
</figure>

<p>The <a href="http://amygdala.github.io/dataflow/app_engine/2017/04/14/gae_dataflow.html">previous post</a> in this series
goes into a bit more detail about what some of the pipeline steps do, and how the pipeline accesses the Datastore.</p>

<p>As part of our new template-ready pipeline definition, we’ll specify that the pipeline takes a
<a href="https://cloud.google.com/dataflow/docs/templates/creating-templates#modifying-your-code-to-use-runtime-parameters">runtime argument</a>, 
named <code class="highlighter-rouge">timestamp</code>. This value is used to filter out tweets N days older than the timestamp, so that the pipeline analyzes
only recent activity.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">class</span> <span class="nc">UserOptions</span><span class="p">(</span><span class="n">PipelineOptions</span><span class="p">):</span>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_add_argparse_args</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
      <span class="n">parser</span><span class="o">.</span><span class="n">add_value_provider_argument</span><span class="p">(</span><span class="s">'--timestamp'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
</code></pre>
</div>

<p>Then, that argument can be accessed at runtime from a template-generated pipeline, as in this snippet:</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="n">user_options</span> <span class="o">=</span> <span class="n">pipeline_options</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">UserOptions</span><span class="p">)</span>
  <span class="o">...</span>
  <span class="n">wc_records</span> <span class="o">=</span> <span class="n">top_percents</span> <span class="o">|</span> <span class="s">'format'</span> <span class="o">&gt;&gt;</span> <span class="n">beam</span><span class="o">.</span><span class="n">FlatMap</span><span class="p">(</span>
      <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[{</span><span class="s">'word'</span><span class="p">:</span> <span class="n">xx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'percent'</span><span class="p">:</span> <span class="n">xx</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                  <span class="s">'ts'</span><span class="p">:</span> <span class="n">user_options</span><span class="o">.</span><span class="n">timestamp</span><span class="o">.</span><span class="n">get</span><span class="p">()}</span> <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">x</span><span class="p">])</span>
</code></pre>
</div>

<p>The example includes a template creation utility script called <a href="https://github.com/amygdala/gae-dataflow/blob/master/job_template_launch/create_template.py"><code class="highlighter-rouge">create_template.py</code></a>, which
sets some pipeline options, including the <code class="highlighter-rouge">--template_location</code> flag, defines the pipeline (via <code class="highlighter-rouge">pipe.process_datastore_tweets()</code>), and calls <code class="highlighter-rouge">run()</code> on it. The core of this script is shown below.
Note that the <code class="highlighter-rouge">pipeline_options</code> dict doesn’t include <code class="highlighter-rouge">timestamp</code>; we’ll define that
at runtime, not compile time.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">dfpipe.pipe</span> <span class="kn">as</span> <span class="nn">pipe</span>
<span class="o">...</span>
<span class="n">pipeline_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'project'</span><span class="p">:</span> <span class="n">PROJECT</span><span class="p">,</span>
    <span class="s">'staging_location'</span><span class="p">:</span> <span class="s">'gs://'</span> <span class="o">+</span> <span class="n">BUCKET</span> <span class="o">+</span> <span class="s">'/staging'</span><span class="p">,</span>
    <span class="s">'runner'</span><span class="p">:</span> <span class="s">'DataflowRunner'</span><span class="p">,</span>
    <span class="s">'setup_file'</span><span class="p">:</span> <span class="s">'./setup.py'</span><span class="p">,</span>
    <span class="s">'job_name'</span><span class="p">:</span> <span class="n">PROJECT</span> <span class="o">+</span> <span class="s">'-twcount'</span><span class="p">,</span>
    <span class="s">'temp_location'</span><span class="p">:</span> <span class="s">'gs://'</span> <span class="o">+</span> <span class="n">BUCKET</span> <span class="o">+</span> <span class="s">'/temp'</span><span class="p">,</span>
    <span class="s">'template_location'</span><span class="p">:</span> <span class="s">'gs://'</span> <span class="o">+</span> <span class="n">BUCKET</span> <span class="o">+</span> <span class="s">'/templates/'</span> <span class="o">+</span> <span class="n">PROJECT</span> <span class="o">+</span> <span class="s">'-twproc_tmpl'</span>
<span class="p">}</span>
<span class="n">pipeline_options</span> <span class="o">=</span> <span class="n">PipelineOptions</span><span class="o">.</span><span class="n">from_dictionary</span><span class="p">(</span><span class="n">pipeline_options</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">process_datastore_tweets</span><span class="p">(</span><span class="n">PROJECT</span><span class="p">,</span> <span class="n">DATASET</span><span class="p">,</span> <span class="n">pipeline_options</span><span class="p">)</span>
</code></pre>
</div>

<p>Because we used the <code class="highlighter-rouge">--template_location</code> flag, a template for that pipeline
is compiled and saved to the indicated GCS location (rather than triggering a run of the pipeline).</p>

<p>Now that the template is created, we can use it to launch Dataflow pipeline jobs from our GAE app.</p>

<h3 id="a-note-on-input-sources-and-template-runtime-arguments">A note on input sources and template runtime arguments</h3>

<p>As you can see from <a href="https://cloud.google.com/dataflow/docs/templates/creating-templates#pipeline-io-and-runtime-parameters">this table</a>
in the documentation, the Dataflow Python SDK does not yet support the use of runtime parameters with Datastore input.</p>

<p>For pipeline analysis, we want to consider only Datastore data from the last N days.
But, because of the above constraint, we can’t access the runtime <code class="highlighter-rouge">timestamp</code> parameter when we’re constructing the
Datastore reader query. (If you try, you will see a compile-time error). Similarly, if you try the approach taken by
the non-template version of the pipeline <a href="https://github.com/amygdala/gae-dataflow/blob/master/sdk_launch/dfpipe/pipe.py">here</a>,
which uses <code class="highlighter-rouge">datetime.datetime.now()</code> to construct its Datastore query, you’ll find that you’re always using the same
compile-time static timestamp each time you run the template.</p>

<p>To work around this for the template version of this pipeline, we will include a filter step, that <em>can</em> access runtime parameters, and which filters out all but the last N days of tweets post-query.
You can see this step as <code class="highlighter-rouge">FilterDate</code> in the Dataflow pipeline graph figure above.</p>

<h3 id="launching-a-dataflow-templated-job-from-the-cloud-console">Launching a Dataflow templated job from the Cloud Console</h3>

<p>Before we actually deploy the GAE app, let’s check that we can launch a properly running Dataflow templated job
from our newly generated template. We can do that by launching a job based on that template from <a href="https://console.cloud.google.com">Cloud
Console</a>.  (You could also do this via the <code class="highlighter-rouge">gcloud</code> command-line tool). Note that the
pipeline won’t do anything interesting unless you already have Tweet data in the Datastore— which would be the case if
you tried the <a href="http://amygdala.github.io/dataflow/app_engine/2017/04/14/gae_dataflow.html">earlier example</a> in this
series— but you can still confirm that it launches and runs successfully.</p>

<p>Go to the <a href="https://console.cloud.google.com/dataflow">Dataflow pane</a> of Cloud Console, and click “Create Job From
Template”.</p>

<figure>
    <a href="https://storage.googleapis.com/amy-jo/images/job_templates1.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/job_templates1.png" width="300" /></a>
    <figcaption><i>Creating a Dataflow job from a template.</i></figcaption>
</figure>

<p>Select “Custom Template”, then browse to your new template’s location in GCS. This info was output when you ran
<code class="highlighter-rouge">create_template.py</code>. (The pulldown menu also includes some predefined templates that you may want to explore later).</p>

<figure>
    <a href="https://storage.googleapis.com/amy-jo/images/job_templates2.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/job_templates2.png" width="400" /></a>
    <figcaption><i>Select "Custom Template", and specify the path to the template file.</i></figcaption>
</figure>

<p>Finally, set your pipeline’s defined runtime parameter(s). In this case, we have one: <code class="highlighter-rouge">timestamp</code>. The pipeline is
expecting a value in a format like this:<br />
<code class="highlighter-rouge">2017-10-22 10:18:13.491543</code> (you can generate such a string in the Python interpreter via <code class="highlighter-rouge">str(datetime.datetime.now())</code>).</p>

<figure>
    <a href="https://storage.googleapis.com/amy-jo/images/job_templates3.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/job_templates3.png" width="400" /></a>
    <figcaption><i>Set your pipeline's runtime parameter(s) before running the job.</i></figcaption>
</figure>

<p>While we don’t show it here, <a href="https://cloud.google.com/dataflow/docs/templates/creating-templates#metadata">you can extend your templates with additional
metadata</a> so that custom parameters may be
validated when the template is executed.</p>

<p>Once you click ‘Run Job’, you should be able to see your job running in Cloud Console.</p>

<h2 id="using-an-app-engine-app-to-periodically-launch-dataflow-jobs-and-fetch-tweets">Using an App Engine app to periodically launch Dataflow jobs (and fetch Tweets)</h2>

<p>Now that we’ve checked that we can successfully launch a Dataflow job using our template, we’ll define an App
Engine app handler to launch such jobs via the Dataflow job template
<a href="https://cloud.google.com/dataflow/docs/reference/rest/#collection-v1b3projectslocationstemplates">REST API</a>, and
run that handler periodically via a GAE cron.
We’ll use another handler of the same app to periodically fetch tweets and store them in the Datastore.</p>

<p>You can see the GAE app script <a href="https://github.com/amygdala/gae-dataflow/blob/master/job_template_launch/main.py">here</a>.<br />
The <code class="highlighter-rouge">FetchTweets</code> handler fetches tweets and stores them in the Datastore.
See the <a href="http://amygdala.github.io/dataflow/app_engine/2017/04/14/gae_dataflow.html">previous post</a> in this series for a bit more info on that.  However, this part of the app is just
for example purposes; in your own apps, you probably already have some other means of collecting and storing data in Datastore.</p>

<p>The <code class="highlighter-rouge">LaunchJob</code> handler is the new piece of the puzzle: using the Dataflow REST API, it sets the <code class="highlighter-rouge">timestamp</code> runtime parameter, and launches a Dataflow job using the template.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">googleapiclient.discovery</span> <span class="kn">import</span> <span class="n">build</span>
<span class="kn">from</span> <span class="nn">oauth2client.client</span> <span class="kn">import</span> <span class="n">GoogleCredentials</span>
<span class="o">...</span>
    <span class="n">credentials</span> <span class="o">=</span> <span class="n">GoogleCredentials</span><span class="o">.</span><span class="n">get_application_default</span><span class="p">()</span>
    <span class="n">service</span> <span class="o">=</span> <span class="n">build</span><span class="p">(</span><span class="s">'dataflow'</span><span class="p">,</span> <span class="s">'v1b3'</span><span class="p">,</span> <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span><span class="p">)</span>

    <span class="n">BODY</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"jobName"</span><span class="p">:</span> <span class="s">"{jobname}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">jobname</span><span class="o">=</span><span class="n">JOBNAME</span><span class="p">),</span>
            <span class="s">"gcsPath"</span><span class="p">:</span> <span class="s">"gs://{bucket}/templates/{template}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">bucket</span><span class="o">=</span><span class="n">BUCKET</span><span class="p">,</span> <span class="n">template</span><span class="o">=</span><span class="n">TEMPLATE</span><span class="p">),</span>
            <span class="s">"parameters"</span><span class="p">:</span> <span class="p">{</span><span class="s">"timestamp"</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">utcnow</span><span class="p">())},</span>
             <span class="s">"environment"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">"tempLocation"</span><span class="p">:</span> <span class="s">"gs://{bucket}/temp"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">bucket</span><span class="o">=</span><span class="n">BUCKET</span><span class="p">),</span>
                <span class="s">"zone"</span><span class="p">:</span> <span class="s">"us-central1-f"</span>
             <span class="p">}</span>
        <span class="p">}</span>

    <span class="n">dfrequest</span> <span class="o">=</span> <span class="n">service</span><span class="o">.</span><span class="n">projects</span><span class="p">()</span><span class="o">.</span><span class="n">templates</span><span class="p">()</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
        <span class="n">projectId</span><span class="o">=</span><span class="n">PROJECT</span><span class="p">,</span> <span class="n">body</span><span class="o">=</span><span class="n">BODY</span><span class="p">)</span>
    <span class="n">dfresponse</span> <span class="o">=</span> <span class="n">dfrequest</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">dfresponse</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">response</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">'Done'</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="launching-the-dataflow-pipeline-periodically-using-a-gae-cron">Launching the Dataflow pipeline periodically using a GAE cron</h2>

<p>For our GAE app, we want to launch a Dataflow templated job every few hours, where each job analyzes the tweets from the past few days, providing a ‘moving window’ of analysis. 
So, it makes sense to set things using a <a href="https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml">cron.yaml</a> file like this:</p>

<div class="language-yaml highlighter-rouge"><pre class="highlight"><code><span class="s">cron</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">description</span><span class="pi">:</span> <span class="s">fetch tweets</span>
  <span class="s">url</span><span class="pi">:</span> <span class="s">/timeline</span>
  <span class="s">schedule</span><span class="pi">:</span> <span class="s">every 17 minutes</span>
  <span class="s">target</span><span class="pi">:</span> <span class="s">default</span>
<span class="pi">-</span> <span class="s">description</span><span class="pi">:</span> <span class="s">launch dataflow pipeline</span>
  <span class="s">url</span><span class="pi">:</span> <span class="s">/launchtemplatejob</span>
  <span class="s">schedule</span><span class="pi">:</span> <span class="s">every 5 hours</span>
  <span class="s">target</span><span class="pi">:</span> <span class="s">default</span>
</code></pre>
</div>

<p>A GAE app makes it easy to run such a cron, but note that now that we’re using templates, it becomes easier to to support this functionality in other ways too.  E.g., it would also be straightforward to use the <code class="highlighter-rouge">gcloud</code> CLI to launch the template job, and set up a local cron job.</p>

<h2 id="a-look-at-the-example-results-in-bigquery">A look at the example results in BigQuery</h2>

<p>Once our example app is up and running, it periodically runs a Dataflow job that writes the results of its analysis to
BigQuery.  (It would also be straightforward to write results to the Datastore if that makes more sense for your
workflow – or to write to multiple sources).</p>

<p>With BigQuery, it is easy to run some fun queries on the data. 
For example, we can find recent word co-occurrences that are ‘interesting’ by our metric:</p>

<figure>
  <a href="https://storage.googleapis.com/amy-jo/images/gae_dataflow/xScreenshot_2017-10-28_14_28_35%20copy%202.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/gae_dataflow/xScreenshot_2017-10-28_14_28_35%20copy%202.png" width="500" /></a>
  <figcaption><i>"Interesting" word co-occurrences</i></figcaption>
</figure>

<p>Or we can look for <em>emergent</em> word pairs, that have become ‘interesting’ in the last day or so (compare April and Oct
2017 results):</p>

<figure>
  <a href="https://storage.googleapis.com/amy-jo/images/gae_dataflow/temp_queries.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/gae_dataflow/temp_queries.png" width="500" /></a>
  <figcaption><i>Emergent (new) interesting word co-occurrences can reflect current news</i></figcaption>
</figure>

<p>We can contrast the ‘interesting’ word pairs with the words that are simply the most popular within a given period (you
can see that most of these words are common, but not particularly newsworthy):</p>

<figure>
  <a href="https://storage.googleapis.com/amy-jo/images/gae_dataflow/pScreenshot_2017-10-28_14_27_05%202.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/gae_dataflow/pScreenshot_2017-10-28_14_27_05%202.png" width="400" /></a>
  <figcaption><i>Popular, but not necessarily interesting words</i></figcaption>
</figure>

<p>Or, find the most frequently tweeted URLs from the past few weeks (some URLs are truncated in the output):</p>

<figure>
  <a href="https://storage.googleapis.com/amy-jo/images/bq_popurls2b.png" target="_blank"><img src="https://storage.googleapis.com/amy-jo/images/bq_popurls2b.png" width="500" /></a>
  <figcaption><i>The most frequently tweeted URLs from the past few weeks (filtering out some of the shortlinks)</i></figcaption>
</figure>

<h2 id="summary-and-whats-next">Summary… and what’s next?</h2>

<p>In this post, we’ve looked at how you can programmatically launch Dataflow pipelines — that read from Datastore — using Cloud Dataflow <a href="https://cloud.google.com/dataflow/docs/templates/overview">job templates</a>, and call the Dataflow
<a href="https://cloud.google.com/dataflow/docs/reference/rest/#collection-v1b3projectslocationstemplates">REST API</a> from an App Engine app.
See the example app’s <a href="https://github.com/amygdala/gae-dataflow/blob/master/job_template_launch/README.md">README</a> for more detail on how to configure and run the app yourself.</p>

<p>Dataflow’s expressive programming model makes it easy to build and support a wide range of scalable processing and
analytics tasks. With templates, it becomes much easier to launch pipeline jobs — you don’t have to recompile every time
you execute, or worry about your environment and dependencies. And it’s more straightforward for less technical users to
launch template-based pipelines.</p>

<p>We hope you find the example app useful as a starting point towards defining new pipeline templates and running
your own analytics — via App Engine apps or otherwise. We look forward to hearing more about what you build!</p>

  </article>

</div>

Tags:
  
    <a href="/tag/dataflow">dataflow</a>&nbsp
  
    <a href="/tag/gae">gae</a>&nbsp
  
</ul>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <!-- <h2 class="footer-heading">Amy on GCP</h2> -->

    <div class="footer-col-wrapper">
      <div class="footer-col  footer-col-1">
        <ul class="contact-list">
          <!-- <li>Amy on GCP</li> -->
          <li><a href="mailto:"></a></li>
        </ul>
      </div>

      <div class="footer-col  footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/amygdala">
              <span class="icon  icon--github">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>

              <span class="username">amygdala</span>
            </a>
          </li>
          

          
          <li>
            <a href="https://twitter.com/amygdala">
              <span class="icon  icon--twitter">
                <svg viewBox="0 0 16 16">
                  <path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                  c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
                </svg>
              </span>

              <span class="username">amygdala</span>
            </a>
          </li>
          
        </ul>
      </div>

      <div class="footer-col  footer-col-3">
        <p class="text"></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
